---
title: "Tear_fluid_ALS_new_dataset"
author: "Clara Meijs"
date: "2022-11-21"
output:
  html_document:
    df_print: paged
    keep_md: yes
    toc: true
    toc_float: true
    toc_collapsed: true
    toc_depth: 5
    theme: lumen
---

This script will take you through the ALS tear fluid project. This project aims to create a diagnostic tool out of the proteomics landscape of tear fluid. The analyses consist of: fitting a model for the new proteomics dataset (n=209), and fitting a model on the western blot data. 

## 0 Preparatory activities

Start with clearing environment and loading packages

```{r libraries, results='hide', message=FALSE,class.source = 'fold-hide'}
rm(list=ls())

library('ggplot2')
library('tidyverse')
library('Rtsne')
library('umap')
library('pheatmap')
library('RColorBrewer')
library("factoextra")
library("viridis")
library("dplyr")
library('caret')
library('ranger')
library('glmnet')
library('pROC')
library('RobustRankAggreg')
library('matrixStats') # row standard deviation
library('fgsea')
library('org.Hs.eg.db')
library('uwot')
library('h2o')
library('kernlab')
library('scales')
library('naniar')
library('plyr')
library('mice')
library('impute')
library('readxl')



# define colours for plots
farben = viridis(2, option="C", direction = -1, begin = 0.2, end = 0.8)
```

Setting directory to correct map and create directory for output:

```{r set-working-directories,message=FALSE,class.source = 'fold-hide'}
# if you are using Rstudio run the following command, otherwise, set the working directory to the folder where this script is in
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

# create directory for results
dir.create(file.path(getwd(),'results'), showWarnings = FALSE)
# create directory for plots
dir.create(file.path(getwd(),'plots'), showWarnings = FALSE)
```

## 1 New Dataset

### 1.1 Data preprocessing 

Load data, and have a look at it

```{r load new data,message=FALSE}
# LOAD DATA
# data frame 1: col names = patientID, protein expression values (rows) and precursor count
# data frame 2: row names = patientID, patientinfo (columns), status column values: Group 1 and Group 2
rm(list=ls())

p_raw_data <- read.delim("data/New_proteomics_data_expression.txt")
p_patient_info <- read.delim("data/New_proteomics_data_patient_overview.tsv", comment.char="#")
p_info <- read_excel("data/new_patient_data_clean.xlsx")

p_d = p_raw_data[,grep("PG.Quantity", colnames(p_raw_data))] 
p_d  = as.data.frame(t(p_d))
p = as.data.frame(matrix(NA, nrow = nrow(p_patient_info), ncol = 2))
colnames(p)=c("group","patid")

for(i in 1:length(p_patient_info$FileName)){
p[i,1] = unlist(strsplit(p_patient_info$FileName[i], split='_', fixed=TRUE))[5]
p[i,2] = unlist(strsplit(p_patient_info$FileName[i], split='_', fixed=TRUE))[7]
}

p[41:42,1] = "B"

```


```{r clean and make numeric, message=FALSE}
p_d[p_d == "Filtered"] = NA 
p_d[p_d == "NaN"] = NA 
for(i in 1:ncol(p_d)){p_d[,i]=str_replace_all(p_d[,i], ",", ".")} #change all commas in dataset to dots
p_d = data.frame(lapply(p_d,as.numeric))
```


```{r divide dataset in two sets and take mean expressions}
p_d = cbind(as.numeric(p$patid),p_d)
colnames(p_d)[1] = "patid"

p_d_A = p_d[p$group=="A",]
p_d_B = p_d[p$group=="B",]

p_d_A <- p_d_A[order(p_d_A[,1]),]
p_d_B <- p_d_B[order(p_d_B[,1]),]

#patient 70 is only present in p_d_A, patient 10 occurs twice in p_d_B
#remove second occurence patient 10
p_d_B = p_d_B[-11,]

v = c(1:max(p_d_A$patid))

p_d = as.data.frame(matrix(data=NA,ncol = ncol(p_d_A), nrow = nrow (p_d_A)))
#take mean of every value, combining dataset A and B
for(j in 1:ncol(p_d)){
  for(i in 1:nrow(p_d)){
    p_d[i,j] = mean(c(
      p_d_A[p_d_A$patid==v[i],j], 
      p_d_B[p_d_B$patid==v[i],j]),
      na.rm=TRUE)
  }}

colnames(p_d)[1] = "patid"
```

```{r clinical data}

clin <- read_excel("data/new_patient_data_clean.xlsx")

#only take patid from the whole name
for(i in 1:length(clin$patid1)){
clin$patid1[i] = unlist(strsplit(clin$patid1[i], split='_', fixed=TRUE))[2]
}
clin$patid1 = as.numeric(clin$patid1)
clin = clin[,-2] #remove patid2 column
clin$onset = as.numeric(clin$onset) # one entry was "1 oder 3" and that has become NA
colnames(clin)[1] = "patid"
clin_stat = as.data.frame(cbind(clin$patid, clin$status))
colnames(clin_stat) = c("patid","status")
clin_stat$patid = as.numeric(clin_stat$patid)

#patient 31 has moved to control, therefore duplicate in table
clin_stat[31,2] = "control"
clin_stat = clin_stat[-107,] #remove duplicate

p_d <- merge(clin_stat, p_d, by = "patid")
rownames(p_d) = p_d$patid

#in dataset, patient 18, 27 and 49 should be removed --> see original patient dataset
p_d = p_d[p_d$patid!=18 & p_d$patid!=27 & p_d$patid!=49 ,]

p_d = p_d[,-1] #remove patid column because it is already in the rownames
```


```{r missing visualization, message=FALSE}
vis_miss(as.data.frame(t(p_d[,2:ncol(p_d)])),warn_large_data = F) #visualise missing new dataset
ggsave("plots/first_vismiss.pdf", width = 11 , height = 8, units = "in")
```


```{r remove variables with too much missing, message=FALSE}
#calculate fraction missing
nmissing <- function(x) sum(is.na(x)/length(x)) #create function to calculate fraction missing of vector
m_ALS = as_vector(colwise(nmissing)(p_d[p_d$status=="ALS",])) #calculate fraction missing in patients with ALS
m_control = as_vector(colwise(nmissing)(p_d[p_d$status=="control",])) #calculate fraction missing in controls

m1 = c(m_ALS>0.33|m_control>0.33)
k1 = c(m_ALS<0.33&m_control<0.33)

#remove status column in the missing and present patterns\
m1 = m1[-1]
k1 = k1[-1]

#split variables according to missingness
m = p_raw_data[m1,1:6] #save variable information for excluded variables
k = p_raw_data[k1,1:6] #save variable information for included variables
p_d = p_d[,m_ALS<0.33&m_control<0.33] #subset dataset with variables that have less than 33% missing

#visualize new dataset
vis_miss(as.data.frame(t(p_d[,2:ncol(p_d)])),warn_large_data = F) #visualise missing new dataset
```

```{r make disease status factor correct}
p_d$status = as.factor(p_d$status)
p_d$status <- factor(p_d$status, levels = c("control", "ALS"))
p_d$status = as.integer(p_d$status)-1 #make status integer with 0 and 1 (group 2 is integer 1)
```


```{r log transform data, message=FALSE}
#look at data
 #minimum and maximum values of protein expression
p_d[1:10,1:10]
dim(p_d)

# Kernel Density Plot
d <- density(unlist(p_d[,2:ncol(p_d)]),na.rm=T)
log.d <- density(log(unlist(p_d[,2:ncol(p_d)])),na.rm=T)
plot(d, main="data distribution")
plot(log.d, main="log-transformed data distribution")

#log transform data
p_d[,2:ncol(p_d)] = log(p_d[,2:ncol(p_d)])

# Kernel Density Plot
d <- density(unlist(p_d[,2:ncol(p_d)]),na.rm=T)
log.d <- density(log(unlist(p_d[,2:ncol(p_d)])),na.rm=T)
plot(d, main="data distribution")
plot(log.d, main="log-transformed data distribution")

#look at data again
min(p_d[,2:ncol(p_d)], na.rm = T);max(p_d[,2:ncol(p_d)], na.rm = T) #minimum and maximum values of protein expression
p_d[1:10,1:10]
dim(p_d)
```

```{r standardize data using z-score}

#look at data
p_d[1:10,1:10]
min(p_d[,2:ncol(p_d)], na.rm = T)   ;max(p_d[,2:ncol(p_d)], na.rm = T)

#perform z-score standardization
p_d_hp = p_d #save unstandardized dataset for heatmap
for(i in 2:ncol(p_d)){
  p_d[,i] = scale(p_d[,i], center = TRUE, scale = TRUE)
}

p_d = as.data.frame(as.matrix(p_d)) # to remove attributes that are causing errors in the mice function

#look at data again
p_d[1:10,1:10]
min(p_d[,2:ncol(p_d)], na.rm = T)   ;max(p_d[,2:ncol(p_d)], na.rm = T)
```

```{r entrez ID}
#get names right background

# first load the data and then put the gene names into a vector called background
background = k[,2]

# fix formatting error from loading csv into R
for(element in background){
  background[background == element] = gsub("\\.","-", element)
}
for(i in 1:length(background)){
  background[i] = unlist(strsplit(background[i], split=';', fixed=TRUE))[1]
}

# check names found in entrez database
library(org.Hs.eg.db)
hs = org.Hs.eg.db
ids = select(hs, 
             keys = background,
             columns = c("ENTREZID", "SYMBOL"),
             keytype = "SYMBOL")

missing_ids = replace = ids[which(is.na(ids$ENTREZID)), "SYMBOL"] # names not found in entrez databank

replace[replace == "C15orf38-AP3S2"] = "ARPIN-AP3S2"
replace[replace == ""] = NA
replace[replace == "hCG_2043426"] = "DDX19B"
replace[replace == "hCG_2039566"] = "H2AB1"
replace[replace == "SARG"] = "C1orf116"


# replace the not found gene names
if(length(ids[which(is.na(ids$ENTREZID)), "SYMBOL"]) == length(replace)){
  i = 1
  for(number in which(is.na(ids$ENTREZID))){
    background[number] = replace[i]
    i = i+1
  }
} else{
  print("error, replace vector does not fit missing gene names")
}

# remove the gene names that are empty ( i.e. I did not figure out which proteins they are supposed to be/ their annotation suggest that they are not mappable)
full_background = background
background = background[!is.na(background)]
write.csv(background, file = 'results/new_background_for_gsea.csv')

# rerun to get final set of EntrezIDs
ids = select(hs, 
             keys = background,
             columns = c("ENTREZID", "SYMBOL"),
             keytype = "SYMBOL")

# double check no NAs are left
ids[which(is.na(ids$ENTREZID)), "SYMBOL"]

# safe entrezIDs of background
background_ids = ids$ENTREZID
```

```{r inspect missing before imputation}
      #inspect missing
      cat((sum(is.na(p_d))/prod(dim(p_d)))*100, "percentage missing") #total percentage missing
      table(round(sort(colMeans(is.na(p_d))*100, decreasing=T),1)) #percentage missing per variable
      
      # delete rows with more than 70% percent missing
      miss <- c()
      for(i in 1:nrow(p_d)) {
        if(length(which(is.na(p_d[i,]))) > 0.7*ncol(p_d)) miss <- append(miss,i) 
      }
      p_d <- p_d[-miss,]
      vis_miss(as.data.frame(t(p_d[,2:ncol(p_d)])),warn_large_data = F) #visualise missing new dataset
      ggsave("plots/second_vismiss.pdf", width = 11 , height = 8, units = "in")
```

```{r add background as colnames}
length(full_background[is.na(full_background)])
v = make.unique(rep("unknown",length(full_background[is.na(full_background)]))) 
full_background[is.na(full_background)] = v

full_background = make.unique(full_background)
colnames(p_d)[2:ncol(p_d)] = full_background
```



```{r imputation and save imputation}
imp = impute.knn(t(p_d) ,k = 10, rowmax = 0.6, colmax = 0.70, maxp = 1500, rng.seed=362436069)

df_ml = as.data.frame(t(imp$data))

cat((sum(is.na(df_ml))/prod(dim(df_ml)))*100, "percentage missing") #total percentage missing

#save for PERSEUS use
write.csv(df_ml, "results/knn_imp_data.csv", row.names=FALSE, quote=FALSE)
df_ml_t = as.data.frame(t(df_ml))
write.csv(as.data.frame(t(df_ml)),"results/knn_imp_data2.csv", row.names=TRUE, quote=FALSE)
```

```{r boxplot of validation proteins}

# df_ml$status = as.factor(df_ml$status)
# levels(df_ml$status) = c("control","ALS")
# df_ml$status <- factor(df_ml$status, levels = c("ALS", "control"))
#       df_ml %>% dplyr::select(status, CRYM, CAPZA2, ALDH16A1, PFKL, SERPINC1, HP) %>%
#             pivot_longer(., cols = c(CRYM, CAPZA2, ALDH16A1, PFKL, SERPINC1, HP), names_to = "Var", values_to = "Val") %>%
#             ggplot(aes(x = Var, y = Val, fill = status)) +
#             geom_boxplot() +
#             ggtitle("Boxplot \nproteomics dataset after knn imputation and standardization") +
#             theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
#   
#       ggsave("plots/boxplot_new_dataset.jpg", width = 11, height = 5, units = "in")
#       ggsave("plots/boxplot_new_dataset.pdf", width = 11, height = 5, units = "in")
# 
#       df_ml %>% dplyr::select(status, CRYM, CAPZA2, ALDH16A1, PFKL, SERPINC1, HP) %>%
#         pivot_longer(., cols = c(CRYM, CAPZA2, ALDH16A1, PFKL, SERPINC1, HP), names_to = "Var", values_to = "Val") %>% ggplot(aes(x = Val, y = Var)) +
#   # horizontal boxplots & density plots
#   geom_boxplot(aes(fill = status)) +
#   geom_density(aes(x = Val,  fill = status), inherit.aes = FALSE) +
#   ggtitle("Boxplot plus density \nproteomics dataset after knn imputation and standardization") +
#   facet_grid(status ~ .) +
#   scale_fill_discrete()
# 
#       ggsave("plots/boxplot_plus_density_new_dataset.jpg", width = 11, height = 5, units = "in")
#       ggsave("plots/boxplot_plus_density_new_dataset.pdf", width = 11, height = 5, units = "in")

```


### 2.2 Unsupervised analysis 

Includes PCA, UMAP, tSNE and heatmap analysis and visualisations

#### 2.2.1 PCA

Perform PCA and create three different plots: a scree plot, a variable plot, and a patient plot

```{r PCA new dataset, results='hide',message=FALSE,fig.show='hide'}

farben = viridis(2, option="C", direction = -1, begin = 0.2, end = 0.8)

# set seed for reproducible results
set.seed(9)

summary(df_ml$status)
df_ml$status =  factor(df_ml$status,labels = c("control","ALS"))
summary(df_ml$status)

# run pca function from base R
pca_patients = prcomp(df_ml[ , !names(df_ml) == "status"], scale = T)

pca_patients = prcomp(df_ml[,2:ncol(df_ml)])
#visualize PCA outcomes
      
    #scree plot

       fviz_screeplot(pca_patients, ncp = 30) #scree plot
       ggsave("plots/new_pca_scree.jpg", width = 6, height = 4, units = "in")
       ggsave("plots/new_pca_scree.pdf", width = 11, height = 8, units = "in")
      
    #PCA variable plot
      
      fviz_pca_var(pca_patients,
                   col.var = "coord", # Color by contributions to the PC
                   gradient.cols = farben,
                   repel = TRUE     # Avoid text overlapping
                   )
      ggsave("plots/new_pca_variables.jpg", width = 6, height = 4, units = "in")
      ggsave("plots/new_pca_variables.pdf", width = 11, height = 8, units = "in")

    # Patient plot

      # extract values to calculate explained Variance of each PC
      pca_summary = summary(pca_patients)$importance
      varExp = round(pca_summary[2,]*100,2)
      # extract values and create data frame for plot
      pca = data.frame(pca_patients$x)
      
      # add status to data frame for plotting
      if(all(rownames(pca) == rownames(df_ml))){
        pca$group = df_ml$status
      }
      
      # plot PCA with patients
      ggplot(pca, aes(x=PC1,y=PC2, colour = as.factor(group))) + 
        geom_point(size = 2) +
        scale_color_manual(name = "Group", labels = c("ctrl", "ALS"), values = farben) +
        xlab(paste("PC1 (",varExp[1],"%)")) + ylab(paste("PC2 (",varExp[2],"%)")) + ggtitle("PCA")
      # save plot
      ggsave("plots/new_pca_patients.jpg", width = 6, height = 4, units = "in")
      ggsave("plots/new_pca_patients.pdf", width = 11, height = 8, units = "in")


```


Tada!

![Scree plot](plots/new_pca_scree.jpg) ![Variables plot](plots/new_pca_variables.jpg) ![Patients plot](plots/new_pca_patients.jpg)

#### 1.2.2 t-SNE {#t-sne}

t-SNE (t-distributed stochastic neighbourhood embedding) is another form
of PCA. t-SNE is also a unsupervised non-linear dimensionality reduction
and data visualization technique. The math behind t-SNE is quite complex
but the idea is simple. It embeds the points from a higher dimension to
a lower dimension trying to preserve the neighborhood of that point.

Unlike PCA it tries to preserve the Local structure of data by
minimizing the Kullback--Leibler divergence (KL divergence) between the
two distributions with respect to the locations of the points in the
map. It is one of the best dimensionality reduction techniques, and
handles outliers better than PCA.

```{r t-SNE, results='hide',message=FALSE,fig.show='hide'}
set.seed(9)

# run tsne function from Rtsne package
tsne_out = Rtsne(df_ml[ , !names(df_ml) == "status"])

# extract values to data frame and add status for plotting
tsne_plot = as.data.frame(tsne_out$Y)
tsne_plot$group = df_ml$status

# plot tSNE
ggplot(tsne_plot) + geom_point(aes(x=V1, y=V2, color = as.factor(group))) + ggtitle("tSNE Patients") +
  scale_color_manual(name = "Group", labels = c("ctrl", "ALS"), values = farben)
# save plot
ggsave("plots/new_tsne.jpg", width = 6, height = 4, units = "in")
ggsave("plots/new_tsne.pdf", width = 11, height = 8, units = "in")
```

![tSNE plot](plots/new_tsne.jpg)

#### 1.2.3 UMAP

UMAP (Uniform Manifold Approximation and Projection) is another
dimensionality reduction approach that can be used for visualisation
similarly to t-SNE, but also for general non-linear dimension reduction.
The algorithm is founded on three assumptions about the data

-   The data is uniformly distributed on Riemannian manifold;

-   The Riemannian metric is locally constant (or can be approximated as
    such);

-   The manifold is locally connected.

```{r UMAP, results='hide',message=FALSE,fig.show='hide'}
# set seed for reproducible results
set.seed(9)

# run umap function from umap package
umap_out = umap::umap(df_ml[,!names(df_ml) == "status"])
# extract values for plot
umap_plot = as.data.frame(umap_out$layout)

# add status to data frame for plotting
if(all(rownames(umap_plot) == rownames(df_ml))){
  umap_plot$group = df_ml$status
}

# plot umap
ggplot(umap_plot) + geom_point(aes(x=V1, y=V2, color = as.factor(group))) +
  ggtitle("umap Patients") +
  scale_color_manual(name = "Group", labels = c("ctrl", "ALS"), values = farben)
# save umap
ggsave("plots/new_umap.jpg", width = 6, height = 4, units = "in")
ggsave("plots/new_umap.pdf", width = 11, height = 8, units = "in")
```

![UMAP plot](plots/new_umap.jpg)

UMAP function contains an option to perform PCA before performing the
UMAP. Repeat UMAP analysis with first reducing the data to 50 PCs. This
way, the UMAP becomes much more powerful. Especially considering the
high dimensionality of the data in comparison with the number of
participants. We need the UMAP function from the 'uwot' package for
this.

```{r PCA-plus-UMAP, results='hide',message=FALSE,fig.show='hide'}


# set seed for reproducible results
set.seed(9)

# run umap function from umap package
umap_out = uwot::umap(df_ml[,!names(df_ml) == "status"], pca = 50)
# extract values for plot
umap_plot = as.data.frame(umap_out)

# add status to data frame for plotting
if(all(rownames(umap_plot) == rownames(df_ml))){
  umap_plot$group = df_ml$status
}

# plot umap
ggplot(umap_plot) + geom_point(aes(x=V1, y=V2, color = as.factor(group))) +
  ggtitle("umap + PCA Patients") +
  scale_color_manual(name = "Group", labels = c("ctrl", "ALS"), values = farben)
# save umap
ggsave("plots/new_umap_PCA.jpg", width = 6, height = 4, units = "in")
ggsave("plots/new_umap_PCA.pdf", width = 11, height = 8, units = "in")
```

![UMAP + PCA plot](plots/new_umap_PCA.jpg)

#### 1.2.4 Auto-encoder {#auto-encoder}

```{r auto-encoder, results='hide',message=FALSE,fig.show='hide'}

h2o.no_progress()  # turn off progress bars
h2o.init(max_mem_size = "5g")  # initialize H2O instance

# Convert mnist features to an h2o input data set
features <- as.h2o(df_ml[,!names(df_ml) == "status"])

# Train an autoencoder
ae1 <- h2o.deeplearning(
  x = seq_along(features),
  training_frame = features,
  autoencoder = TRUE,
  hidden = 3,
  activation = 'Tanh',
  sparse = TRUE
)

# Extract the deep features
ae1_codings <- h2o.deepfeatures(ae1, features, layer = 1)

# extract values for plot
ae1_plot = as.data.frame(ae1_codings)

# add status to data frame for plotting
#if(all(rownames(ae1_plot) == rownames(df_ml))){
#  ae1_plot$group = df_ml$status
#}

ae1_plot$group = df_ml$status 

# plot umap
ggplot(ae1_plot) + geom_point(aes(x=DF.L1.C1, y=DF.L1.C2, color = as.factor(group))) +
  ggtitle("Auto-encoder Patients") +
  scale_color_manual(name = "Group", labels = c("ctrl", "ALS"), values = farben)
# save umap
ggsave("plots/new_autoencoder.jpg", width = 6, height = 4, units = "in")
ggsave("plots/new_autoencoder.pdf", width = 11, height = 8, units = "in")

```

#### 1.2.5 clustering for clinical variables

```{r add clinical variables to dataset}
p_d2 = df_ml
p_d2$patid = rownames(p_d2)
clin2 = clin[-31,] #remove duplicate patient #31 who moved to control
clin2 = clin2[clin2$patid %in% as.numeric(p_d2$patid), ] # select only patient already present in the main dataset

p_d2 = merge(clin2, p_d2, by = "patid")

p_d2$sex[p_d2$sex==1] = "m"
p_d2$sex[p_d2$sex==0] = "w"
p_d2$onset[p_d2$onset==1] = "spinal"
p_d2$onset[p_d2$onset==2] = "bulbar"
p_d2$onset[p_d2$onset==3] = "axial"
```

```{r UMAP clustering on sex, results='hide', message=FALSE, fig.show='hide'}

# set seed for reproducible results
set.seed(9)

# run umap function from umap package
umap_out = umap::umap(p_d2[,!names(p_d2) == c("patid","age","sex","status.x","onset","status.y")])
# extract values for plot
umap_plot = as.data.frame(umap_out$layout)

# add status to data frame for plotting
if(all(rownames(umap_plot) == rownames(p_d2))){
  umap_plot$group = p_d2$sex
}

# plot umap
ggplot(umap_plot) + geom_point(aes(x=V1, y=V2, color = as.factor(group))) +
  ggtitle("umap Patients") +
  scale_color_manual(name = "Group", labels = c("man", "woman"), values = farben)
# save umap
ggsave("plots/new_umap_clin_sex.jpg", width = 6, height = 4, units = "in")
ggsave("plots/new_umap_clin_sex.pdf", width = 11, height = 8, units = "in")
```

```{r UMAP clustering on age, results='hide', message=FALSE, fig.show='hide'}

# set seed for reproducible results
set.seed(9)
p_d3 = p_d2

#create categorical age variable
m = median(p_d3$age) #median age is 60
p_d3$age[p_d3$age<m] = 0
p_d3$age[p_d3$age>=m] = 1

# run umap function from umap package
umap_out = umap::umap(p_d3[,!names(p_d3) == c("patid","age","sex","status.x","onset","status.y")])
# extract values for plot
umap_plot = as.data.frame(umap_out$layout)

# add status to data frame for plotting
if(all(rownames(umap_plot) == rownames(p_d3))){
  umap_plot$group = p_d3$age
}

# plot umap
ggplot(umap_plot) + geom_point(aes(x=V1, y=V2, color = as.factor(group))) +
  ggtitle("umap Patients") +
  scale_color_manual(name = "Group", labels = c("<60 years", "60 years or older"), values = farben)
# save umap
ggsave("plots/new_umap_clin_age.jpg", width = 6, height = 4, units = "in")
ggsave("plots/new_umap_clin_age.pdf", width = 11, height = 8, units = "in")
```

```{r UMAP clustering on onset, results='hide', message=FALSE, fig.show='hide'}
# set seed for reproducible results
set.seed(9)

p_d3 = p_d2[p_d2$status.x=="ALS",]

# run umap function from umap package
umap_out = umap::umap(p_d3[,!names(p_d3) == c("patid","age","sex","status.x","onset","status.y")])
# extract values for plot
umap_plot = as.data.frame(umap_out$layout)

# add status to data frame for plotting
if(all(rownames(umap_plot) == rownames(p_d3))){
  umap_plot$group = p_d3$onset
}

# plot umap
ggplot(umap_plot) + geom_point(aes(x=V1, y=V2, color = as.factor(group))) +
  ggtitle("umap Patients") +
  scale_color_manual(name = "Group", labels = c("axial", "bulbar","spinal","NA"), values = viridis(4, option="C"))
# save umap
ggsave("plots/new_umap_clin_onset.jpg", width = 6, height = 4, units = "in")
ggsave("plots/new_umap_clin_onset.pdf", width = 11, height = 8, units = "in")
```



### 1.3 Heatmap

To get an idea of how the protein expressions are distributed, we
construct a heatmap

```{r heatmap, results='hide',fig.show='hide'}
 
#functions for saving the heatmaps as figures
        
        save_pheatmap_pdf <- function(x, filename, width=11, height=8) {
           stopifnot(!missing(x))
           stopifnot(!missing(filename))
           pdf(filename, width=width, height=height)
           grid::grid.newpage()
           grid::grid.draw(x$gtable)
           dev.off()
        }
        
        save_pheatmap_jpg <- function(x, filename, width=600, height=400) {
           stopifnot(!missing(x))
           stopifnot(!missing(filename))
           jpeg(filename, width=width, height=height)
           grid::grid.newpage()
           grid::grid.draw(x$gtable)
           dev.off()
        }
        
        make_pheatmap <- function(data, cluster_cols){
          p = pheatmap::pheatmap(data, name = "expression",cutree_cols = 1,
                 show_colnames = T,
                 show_rownames = FALSE,
                 fontsize = 6,
                 annotation_col = annotation,
                 annotation_colors = annotation_colours,
                 color = viridis::viridis(100, option="C", direction = -1,),
                 main = "Heatmap",
                 border_color=NA,
                 cluster_cols = cluster_cols)
          return(p)
        }

# get annotations ready
        
        annotation = data.frame(group = as.factor(p_d2$status.x), 
                                sex = as.factor(p_d2$sex), 
                                age = as.numeric(p_d2$age),
                                onset = as.factor(p_d2$onset))
        rownames(annotation) = rownames(p_d2)
        annotation_colours <- list(
          group = c(control = "#000000", ALS = "#B2182B"), 
          sex = c(w = "lightpink1", m ="skyblue1"), 
          age = c("white", "darkgreen"),
          onset = c(spinal = "yellow", bulbar = "orange", axial = "red"))
        
        p_d3 = p_d2
        p_d_m = data.matrix(p_d2)
        rownames(p_d_m) = rownames(p_d2)


# save and plot heatmap without grouping 
        p = make_pheatmap(data = t(p_d_m[,7:ncol(p_d_m)]), cluster_cols = T)
        
        save_pheatmap_pdf(p, "plots/new_heatmap.pdf")
        
        save_pheatmap_jpg(p, "plots/new_heatmap.jpg")

# heatmap grouped according to onset

        p_d3 = p_d2[order(abs(as.numeric(as.factor(p_d2$onset))), decreasing = FALSE), ]
        p_d_m = data.matrix(p_d3)
        rownames(p_d_m) = rownames(p_d3)
        
        p = make_pheatmap(data = t(p_d_m[,7:ncol(p_d_m)]), cluster_cols = F)
        
        save_pheatmap_pdf(p, "plots/new_heatmap_onset.pdf")
        
        save_pheatmap_jpg(p, "plots/new_heatmap_onset.jpg")

# heatmap grouped according to sex

        p_d3 = p_d2[order(abs(as.numeric(as.factor(p_d2$sex))), decreasing = FALSE), ]
        p_d_m = data.matrix(p_d3)
        rownames(p_d_m) = rownames(p_d3)
        
        p = make_pheatmap(data = t(p_d_m[,7:ncol(p_d_m)]), cluster_cols = F)
        
        save_pheatmap_pdf(p, "plots/new_heatmap_sex.pdf")
        
        save_pheatmap_jpg(p, "plots/new_heatmap_sex.jpg")

# heatmap grouped according to age

        p_d3 = p_d2[order(abs(p_d2$age), decreasing = FALSE), ]
        p_d_m = data.matrix(p_d3)
        rownames(p_d_m) = rownames(p_d3)
        
        p = make_pheatmap(data = t(p_d_m[,7:ncol(p_d_m)]), cluster_cols = F)
        
        save_pheatmap_pdf(p, "plots/new_heatmap_age.pdf")
        
        save_pheatmap_jpg(p, "plots/new_heatmap_age.jpg")

```

![Heatmap](plots/new_heatmap.jpg)

```{r heatmap with 100 most variable proteins,  results='hide',fig.show='hide'}

# without grouping variable

        d = t(p_d_m[,7:ncol(p_d_m)])
        d2 = head(order(rowVars(d),decreasing = T),100)
        dim(d[d2,])
        
        # save and plot heatmap
        p = make_pheatmap(data = d[d2,], cluster_cols = T)
        
        save_pheatmap_pdf(p, "plots/new_heatmap_mostvar.pdf")
        save_pheatmap_jpg(p, "plots/new_heatmap_mostvar.jpg")
        
# with onset as grouping variable
        
        p_d3 = p_d2[order(abs(as.numeric(as.factor(p_d2$onset))), decreasing = FALSE), ]
        p_d_m = data.matrix(p_d3)
        rownames(p_d_m) = rownames(p_d3)
        
        d = t(p_d_m[,7:ncol(p_d_m)])
        d2 = head(order(rowVars(d),decreasing = T),100)
        dim(d[d2,])
        
        # save and plot heatmap
        p = make_pheatmap(data = d[d2,], cluster_cols = F)
        
        save_pheatmap_pdf(p, "plots/new_heatmap_mostvar_onset.pdf")
        save_pheatmap_jpg(p, "plots/new_heatmap_mostvar_onset.jpg")
        
# with sex as grouping variable
        
        p_d3 = p_d2[order(abs(as.numeric(as.factor(p_d2$sex))), decreasing = FALSE), ]
        p_d_m = data.matrix(p_d3)
        rownames(p_d_m) = rownames(p_d3)
        
        d = t(p_d_m[,7:ncol(p_d_m)])
        d2 = head(order(rowVars(d),decreasing = T),100)
        dim(d[d2,])
        
        # save and plot heatmap
        p = make_pheatmap(data = d[d2,], cluster_cols = F)
        
        save_pheatmap_pdf(p, "plots/new_heatmap_mostvar_sex.pdf")
        save_pheatmap_jpg(p, "plots/new_heatmap_mostvar_sex.jpg")
        
# with age as grouping variable
        
        p_d3 = p_d2[order(abs(p_d2$age), decreasing = FALSE), ]
        p_d_m = data.matrix(p_d3)
        rownames(p_d_m) = rownames(p_d3)
        
        d = t(p_d_m[,7:ncol(p_d_m)])
        d2 = head(order(rowVars(d),decreasing = T),100)
        dim(d[d2,])
        
        # save and plot heatmap
        p = make_pheatmap(data = d[d2,], cluster_cols = F)
        
        save_pheatmap_pdf(p, "plots/new_heatmap_mostvar_age.pdf")
        save_pheatmap_jpg(p, "plots/new_heatmap_mostvar_age.jpg")

```

![Heatmap](plots/new_heatmap_mostvar.jpg)
### 1.4 Univariate analysis 

```{r perform DE analysis with limma}
      library(limma)
      library(IceR)

      # perform DE       
            DE = LIMMA_analysis(
                data = as.data.frame(t(df_ml[,2:ncol(df_ml)])),
                assignments = df_ml[,1])
            
      write.csv(DE, file = 'results/DE_analysis.csv')
```


### 1.5 In-house developed functions

Jenny developed several functions to perform all upcoming analyses. In entails following functions: 

- runML()

- calculateROC()

- plotWeights()

- gsea()

- auccurve()

#### 1.5.1 runML()

All 3 machine learning algorithms can be run with the runML() function from the [functions](/functions.R) script. Usage of the function and analysis including plotting of results and extracting feature weight/importance where possible, can be found in the [ml_github.R](/ml_github.R) script.
The functions takes the following arguments

* data_frame: data as data frame with a status column,

* algorithm: 'lm', 'rf', 'svm lin' or 'svm rad',

* cv: cross validation folds (default = 10),

* BS_number: number of bootstrap runs (default = 1)


 and returns a list of models, importance, predictions (probability), predictions (raw), indices (which samples had been used for training)
 
```{r runML function, results='hide',class.source = 'fold-hide'}
###       boot strap function       ###
# runs machine learning on data with selected algorithm ( 'lm' (linear regression) or
#                                                         'rf' (random forest) or
#                                                         'svm lin' Support Vector Machine + linear kernel)
#                                                         'svm rad' Support Vector Machine + radial kernel))
# number of folds for cross validation (default = 10) and boot strap loops (default = 1)
#
# returns list objects with models, importance, predictions (raw and probability) and indices (samples used for training)


runML = function(data_frame,algorithm, cv = 10, BS_number = 1){
  #check input
  stopifnot('Last argument (BS_number) is not a number.' = is.numeric(BS_number),
            'Number given for cross validation is not a number ,' = is.numeric(cv),
            'Data is not a dataframe.' = is.data.frame(data_frame),
            'status column of df not correct' = all(df_ml$status == 1 | df_ml$status == 0),
            'unknown algorithm. please select \'lm\',\'rf\',\'svm rad\' or \'svm lin\' ' = algorithm %in% c('lm','rf','svm rad','svm lin'))
  
  key_output = c('linear regressio (lasso)','random forest', 'Support Vector Machine (radial kernel)', 'Support Vector Machine (linear kernel)')
  names(key_output) = c('lm','rf','svm rad','svm lin')
  # Output parameters for user check
  print(paste0('Running a ',BS_number,'x boot strap with a ',cv,' fold cross validation. Algorithm is ', key_output[[algorithm]]))
  
  data_frame$status = as.factor(make.names(data_frame$status)) # caret needs prediction variable to have name; turns 0 -> X0 and 1 -> X1
  
  # create lists to save results from bs
  models = list()
  importance = list()
  predictions = list()
  indices = list()
  predictions_raw = list()
  smp_size = floor(0.8 * nrow(data_frame)) # use 80% of data for training, 20% for testing
  
  #set the right parameters for each algo
  if(algorithm == 'lm'| algorithm == 'svm rad' | algorithm == 'svm lin'){
    ctrl = trainControl(method="cv",   
                        number = cv,        
                        summaryFunction=twoClassSummary,   # Use AUC to pick the best model
                        classProbs=TRUE,savePredictions = TRUE)
  }
  else if(algorithm == 'rf'){
    
    n_features = ncol(data_frame[ ,!names(data_frame) == 'status'])
    ctrl = trainControl(method = "cv", 
                        number = cv, 
                        search = 'grid',classProbs = TRUE, savePredictions = TRUE, summaryFunction=twoClassSummary )
  }
  
  # run machine learning
  for(i in 1:BS_number){
  
    train_ind = sample(seq_len(nrow(data_frame)), size = smp_size)
    train = data_frame[train_ind, ]
    test = data_frame[ -train_ind,!names(data_frame) == "status"]
    
    if (algorithm == 'lm'){
      model = train(x=train[ , !names(train) == "status"],
                    y= train$status,
                    method = "glmnet", family = "binomial", tuneLength = 5, metric = "ROC",
                    trControl = ctrl,
                    tuneGrid=expand.grid(
                      .alpha=1, # alpha 1 == lasso
                      .lambda=seq(0, 100, by = 0.1))
      )
    }
    
    else if (algorithm == 'rf'){
      tunegrid = expand.grid(
        .mtry = c(2, 3, 4, 7, 11, 17, 27, floor(sqrt(n_features)), 41, 64, 99, 154, 237, 367, 567, 876),
        .splitrule = c("extratrees","gini"),
        .min.node.size = c(1,2,3,4,5)
      )
      
      model = train(x=train[ , !names(train) == "status"],
                    y= train$status,
                    tuneGrid = tunegrid, 
                    method = "ranger",  tuneLength = 15, metric = "ROC",
                    num.trees = 500,
                    trControl = ctrl,
                    importance = 'impurity'
      )
    }
    
    else if (algorithm == 'svm lin'){
      model = train(x=train[ , !names(train) == "status"],
                    y= train$status,
                    method = "svmLinear", tuneLength = 5, metric = "ROC",
                    trControl = ctrl,
      )
    }
    
    else if (algorithm == 'svm rad'){
      model = train(x=train[ , !names(train) == "status"],
                    y= train$status,
                    method = "svmRadial", tuneLength = 5, metric = "ROC",
                    trControl = ctrl,
      )
    }
    
    models[[i]] = model
    importance[[i]] = varImp(model)
    predictions[[i]] = predict(model, newdata = test,type = "prob")
    predictions_raw[[i]] = predict(model, newdata = test,type = "raw")
    indices[[i]] = train_ind
    print(paste0('finshed loop #',i)) # keep track of what is happening
  }
  return_list = list(models,importance,predictions,predictions_raw,indices)
  names(return_list) = c('models','importance','predictions','predictions_raw','indices')
  return(return_list)
}
```

#### 1.5.2 calculateROC()


```{r calculateROC function + jpeg, results='hide',class.source = 'fold-hide'}
###       calculate averaged ROC curve        ###
# plots and returns data frame for averaged ROC curve from data and result from runML (indices, predictions (raw and probable))

calculateROC_jpeg = function(list_from_ML, data_frame, plot_path_pdf = FALSE, plot_path_jpeg){
  
  # extract needed lists from ML data
  indices = list_from_ML[['indices']]
  predictions = list_from_ML[['predictions']]
  predictions_raw = list_from_ML[['predictions_raw']]
  
  # create one data frame to compare predicted vs actual status
  predictions_compare = data.frame()
  for(i in 1:length(indices)){
    adding = data.frame(Class = data_frame$status[-indices[[i]]], predicted = predictions[[i]]$X0, resample = paste0("run ", i), auc = glmnet:::auc(data_frame$status[-indices[[i]]], predictions_raw[[i]]))
    predictions_compare = rbind(predictions_compare,adding)
  }
  
  # calculate ROC for each run
  rocc = data.frame()
  auc = c()
  for(run in unique(predictions_compare$resample)){
    onefold = dplyr::filter(predictions_compare, resample == run)
    auc = c(auc,onefold$auc[1])
    roc_run = roc(onefold$Class, onefold$predicted, direction = ">")
    rocc = rbind(rocc, data.frame(Sp = roc_run$specificities, Sn = roc_run$sensitivities, n = rep(1:length(roc_run$sensitivities))))
  }
  
  # aggregate the results and create new data frame
  Sp = aggregate(Sp ~ n, rocc, mean)$Sp
  Sn = aggregate(Sn ~ n, rocc, mean)$Sn
  errorSp = aggregate(Sp ~ n, rocc, sd)$Sp
  errorSn = aggregate(Sn ~ n, rocc, sd)$Sn
  plotci = data.frame(Sp,Sn,errorSp,errorSn)
  
  # plot if path is given
  if(plot_path_pdf != FALSE & plot_path_jpeg != FALSE){
    
    #pdf
    pdf(plot_path_pdf,paper="a4r", width = 11, height = 8)
    print(ggplot(plotci, aes(x=(1-Sp),y=Sn)) + geom_line(aes(color = "darkorange")) + theme_bw() +
      ggtitle("mean ROC curve and 95 % CI") +
      geom_ribbon(aes(ymin = (Sn - 0.95*errorSn), ymax = (Sn + 0.95*errorSn), xmin = (1-Sp - 0.95*errorSp), xmax = (1-Sp + 0.95*errorSp),
                      fill = "#B2B2B2"), alpha = 0.5) +
      #   scale_y_continuous(expand = c(0,0), limits = c(0,1.02)) + scale_x_continuous(expand = c(0,0), limits = c(-0.01,1)) +
      scale_color_manual(name = NULL, label = "mean", values = c("darkorange")) +
      scale_fill_manual(name = NULL, label = "95 % CI", values = c('#B2B2B2') ) +
      annotate("text", x = 0.2, y = 0.8, label = paste("mean AUC: ", round(mean(auc),2), "\u00B1 ", round(sd(auc),2)) ) +
      geom_abline(slope = 1, color="darkgrey", alpha = 0.3))
    dev.off()
    
    #jpeg
    jpeg(plot_path_jpeg, width = 900, height = 600)
    print(ggplot(plotci, aes(x=(1-Sp),y=Sn)) + geom_line(aes(color = "darkorange")) + theme_bw() +
      ggtitle("mean ROC curve and 95 % CI") +
      geom_ribbon(aes(ymin = (Sn - 0.95*errorSn), ymax = (Sn + 0.95*errorSn), xmin = (1-Sp - 0.95*errorSp), xmax = (1-Sp + 0.95*errorSp),
                      fill = "#B2B2B2"), alpha = 0.5) +
      #   scale_y_continuous(expand = c(0,0), limits = c(0,1.02)) + scale_x_continuous(expand = c(0,0), limits = c(-0.01,1)) +
      scale_color_manual(name = NULL, label = "mean", values = c("darkorange")) +
      scale_fill_manual(name = NULL, label = "95 % CI", values = c('#B2B2B2') ) +
      annotate("text", x = 0.2, y = 0.8, label = paste("mean AUC: ", round(mean(auc),2), "\u00B1 ", round(sd(auc),2)) ) +
      geom_abline(slope = 1, color="darkgrey", alpha = 0.3))
    dev.off()
  }
  
  return(plotci)
  
}
```
#### 1.5.3 plotWeights()


```{r plotWeights function + jpeg, results='hide',class.source = 'fold-hide'}
###       Extract weights/importance and plot their average       ###
# plots top n (default = 50) proteins by averaged weight/importance
# returns plot (if path is given) and data frame

plotWeights_jpeg = function(list_from_ML, plot_path_pdf = FALSE, plot_path_jpeg = FALSE, number = 50){
  # extract models to continue based on which algorithm input is from
  models = list_from_ML[['models']]
  
  ## linear regression ##
  if(models[[1]]$method == 'glmnet'){ 
    importance = list_from_ML[['importance']]
    
    # extract weights from all models
    coefficient = list()
    for(i in 1:length(models)){
      coefficient[[i]] = coef.glmnet(models[[i]]$finalModel, models[[i]]$bestTune$lambda)
    }
    
    #sort the weights
    weights_lm = vector("list",0)
    for (i in 1:length(coefficient)) {
      for (j in 1:length(coefficient[[i]])) {
        if(j == 1 || coefficient[[i]][j,1] == 0){ # skip intercept
          next
        }
        else if (row.names(coefficient[[i]])[j] %in% names(weights_lm)) { # protein already has a list -> append vector with value
          weights_lm[[row.names(coefficient[[i]])[j]]] = c(weights_lm[[row.names(coefficient[[i]])[j]]],coefficient[[i]][j,1])
        }
        else if (! row.names(coefficient[[i]])[j] %in% names(weights_lm)) {
          weights_lm[[row.names(coefficient[[i]])[j]]] = c(coefficient[[i]][j])
        }
        else{
          print("Failed to extract weights from linear regression model")
          break
        }
      }
    }
    
    # calculate statistics and put into data frame
    avg = c()
    error = c()
    picks = c()
    for (i in 1:length(weights_lm)) {
      avg = c(avg,mean(weights_lm[[i]]))
      error = c(error, sd(weights_lm[[i]]))
      picks = c(picks,length(weights_lm[[i]]))
    }
    
    weight = data.frame(avg,error, picks,row.names=names(weights_lm))
    weight = weight[which(abs(weight$avg)>abs(weight$error) & weight$picks > 1), ]
    
    weight = weight[order(abs(weight$avg), decreasing = TRUE), ]
    name = 'weight'
  }
  
  ## random forest ##
  else if(models[[1]]$method == 'ranger'){ 
    rf_imp = list_from_ML[['importance']]
    
    # create data frame with names for all proteins
    weight = data.frame(row.names = row.names(rf_imp[[1]]$importance))
    
    # fill data frame
    for(i in 1:length(rf_imp)){
      weight = cbind(weight, rf_imp[[i]]$importance, by = "row.names")
      weight$by = NULL
      names(weight)[names(weight) == "Overall"] = paste("run",i, sep = "")
    }
    
    # calculate statistics into data frame
    weight$avg = rowMeans(weight)
    weight$error = rowSds(as.matrix(weight[,-(ncol(weight))]))
    
    weight = weight[order(weight$avg, decreasing = TRUE), ]
    name = 'importance'
  }
  
  ## svm linear kernel ##
  else if(models[[1]]$method == 'svmLinear'){ 
    # calculate weights for each run
    for(i in 1:length(models)){
      coef = models[[i]]$finalModel@coef[[1]]
      matr = models[[i]]$finalModel@xmatrix[[1]]
      
      weig = as.data.frame(coef %*% matr)
      
      if(i == 1){
        weight = weig
      }
      else if(i>1 & all(names(weig) == names(weight))){
        weight = rbind(weight,weig)
      }
      else{
        print(paste(i," ERROR: failed to extract protein weights from SVM linear; differing protein names between runs "))
      }
    }
    
    # calculate statistics and add to data frame
    weight= t(as.data.frame(weight))
    
    weight2 = as.data.frame(matrix(ncol = 2, nrow = nrow(weight), dimnames = 
                                     list(rownames(weight),c("avg","error"))))
    
    weight2$avg = rowMeans(weight)
    weight2$error = rowSds(weight)
    
    weight = weight2[order(abs(weight2$avg), decreasing = TRUE), ]
    name = 'weight'
  }
  
  # plot if path is given
  if(plot_path_pdf != FALSE & plot_path_jpeg != FALSE){
    
    #pdf 
    pdf(plot_path_pdf,paper="a4r", width = 11, height = 8)
    print(ggplot(weight[1:number, ], aes(x = reorder(rownames(weight[1:number, ]),avg), y = avg, fill = avg > 0)) +
            geom_bar(stat = "identity")+
            geom_errorbar( aes(x=reorder(rownames(weight[1:number, ]),avg), ymin=avg-error, ymax=avg+error, colour="#287D8EFF"), width=0.2, alpha=0.9, size=1.2) +
            xlab("Gene names") +
            ylab(name) +
            ggtitle(paste("Mean ",name," and standard deviation; ",models[[1]]$method)) +
            theme_classic() +
            theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
            scale_x_discrete(labels = abbreviate) + 
            scale_fill_manual(name = NULL, label = NULL, values = c("darkorange", "darkgrey")) +
            scale_color_manual(name = NULL, label = "standard deviation", values = c("darkblue")) +
            guides(fill = 'none', colour = 'none'))
    dev.off()
    
    #jpeg
    jpeg(plot_path_jpeg, width = 900, height = 600)
    print(ggplot(weight[1:number, ], aes(x = reorder(rownames(weight[1:number, ]),avg), y = avg, fill = avg > 0)) +
            geom_bar(stat = "identity")+
            geom_errorbar( aes(x=reorder(rownames(weight[1:number, ]),avg), ymin=avg-error, ymax=avg+error, colour="#287D8EFF"), width=0.2, alpha=0.9, size=1.2) +
            xlab("Gene names") +
            ylab(name) +
            ggtitle(paste("Mean ",name," and standard deviation; ",models[[1]]$method)) +
            theme_classic() +
            theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
            scale_x_discrete(labels = abbreviate) + 
            scale_fill_manual(name = NULL, label = NULL, values = c("darkorange", "darkgrey")) +
            scale_color_manual(name = NULL, label = "standard deviation", values = c("darkblue")) +
            guides(fill = 'none', colour = 'none'))
    dev.off()
  }
  return(weight)
}
```
#### 1.5.4 gsea()



```{r gsea_jpeg function, results='hide',class.source = 'fold-hide'}
###       Run Gene Set Enrichment analysis on given background and vector of genes       ###
# plots top n (default = 20) enriched KEGG pathways
# returns plot (if path is given) and data frame

gsea_jpeg = function(genes, min_size = 3,plot_path_pdf = FALSE, plot_path_jpeg = FALSE, number = 20, entrezID = FALSE, background){
  stopifnot('minSize has to be a number' = is.numeric(min_size),
            'background has to be a vector of type character' = is.vector(background, mode = 'character'),
            'genes has to be a named vector with numeric value' = is.vector(genes, mode = 'numeric') & !any(is.na(names(genes))) | missing(background) )
  
  ## load pathways
  kegg_pathways = gmtPathways("data/c2.cp.kegg.v7.5.1.entrez.gmt")
  
  ## get entrezID of background and filter pathways
  # set mapping direction
  keyt = ifelse(entrezID == FALSE, 'SYMBOL', 'ENTREZID')
  
  if(!missing(background)){
    ids_b = AnnotationDbi::select(org.Hs.eg.db, 
                   keys = background,
                   columns = c("ENTREZID", "SYMBOL"),
                   keytype = keyt)
    background_id = ids_b$ENTREZID
    # let user now if certain proteins were excluded due to not mapped EntrezID
    if(any(is.na(background_id))){
      background_id = background_id[!is.na(background_id)]
      print(paste0('Could not find EntrezID for ', ids_b$SYMBOL[which(is.na(ids_b$ENTREZID))]),'. These will be ignored in further analysis.')
    }
    
    # filter KEGG pathways
    for(i in c(1:length(kegg_pathways))){
      kegg_pathways[[i]] = kegg_pathways[[i]][which(kegg_pathways[[i]] %in% background_id)]
    }
  }
  
  ## get entrezID of genes
  ids_g = AnnotationDbi::select(org.Hs.eg.db, 
                 keys = names(genes),
                 columns = c("ENTREZID", "SYMBOL"),
                 keytype = keyt)
  
  gene_id = ids_g$ENTREZID
  names(genes) = gene_id
  
  # let user now if certain proteins were excluded due to not mapped EntrezID
  if(any(is.na(ids_g$ENTREZID))){
    genes = genes[!is.na(names(genes))]
    print(paste0('Could not find EntrezID for', ids_g$SYMBOL[which(is.na(ids_g$ENTREZID))],'. These will be ignored in further analysis.' ))
  }
  
  ## run fgsea()
  # set scoreType depending on data 
  scoret = ifelse(all(genes >= 0), 'pos','std')
  
  fgsea_results = fgsea(pathways = kegg_pathways,
                        stats    = genes,
                        minSize  = min_size,
                        maxSize  = 500,
                        scoreType = scoret)
  
  # calculate number of genes in pathways 
  fgsea_results$count = sapply(fgsea_results$leadingEdge,length)
  # with small gene sample count is sometimes 0 -> filter
  fgsea_results = fgsea_results[fgsea_results$count != 0, ]
  
  # store gene names, not just IDs in column
  if(!missing(background)){
    fgsea_results$geneNames =   sapply(fgsea_results$leadingEdge, function(x) paste0(ids_g$SYMBOL[which(ids_g$ENTREZID %in% x)], collapse = ', '))
  }
  
  # get the actual length of the pathways as column
  length_pathways = as.data.frame(lapply(kegg_pathways,length))
  length_pathways = as.data.frame(t(length_pathways))
  names(length_pathways) = 'pathwaySize'
  length_pathways$pathway = row.names(length_pathways)
  
  # merge into one df 
  fgsea_results = merge(fgsea_results,length_pathways, by = "pathway")
  
  # plot if path is given
  if(plot_path_pdf != FALSE & plot_path_jpeg != FALSE){
    
    #pdf
    pdf(plot_path_pdf,paper="a4r", width = 11, height = 8)
    print(ggplot(fgsea_results[order(fgsea_results$padj), ][1:number, ], aes(x = -log10(padj), y = reorder(pathway, -padj), fill = padj)) +
      geom_bar(stat = "identity") +
      xlab("- log(p-value)") +
      ylab("Functional category") +
      ggtitle("KEGG terms") +
      labs(fill = "FDR value") +
      scale_fill_viridis(option = "E")+ 
      geom_text(aes(label = paste0(count, "/", pathwaySize)), hjust=-0.15, size =3.5)+ 
      xlim(0, max(-log10(fgsea_results$padj))+0.02))
    dev.off()
    
    #jpeg
    jpeg(plot_path_jpeg,width = 900, height = 600)
    print(ggplot(fgsea_results[order(fgsea_results$padj), ][1:number, ], aes(x = -log10(padj), y = reorder(pathway, -padj), fill = padj)) +
      geom_bar(stat = "identity") +
      xlab("- log(p-value)") +
      ylab("Functional category") +
      ggtitle("KEGG terms") +
      labs(fill = "FDR value") +
      scale_fill_viridis(option = "E")+ 
      geom_text(aes(label = paste0(count, "/", pathwaySize)), hjust=-0.15, size =3.5)+ 
      xlim(0, max(-log10(fgsea_results$padj))+0.02))
    dev.off()
    
  }
  
  return(fgsea_results)
}
```

#### 1.5.5 auccurve()

```{r auccurve function, results='hide',class.source = 'fold-hide'}
### AUC curve of linear model from previously calculated weights
# calculates AUC of a linear model on a data set (protein_data) based on a given protein combination with average weights from previous linear model boot strapping
# returns data frame for plotting combinations to auc
auccurve = function(vectornames,weight_data,protein_data, maxn, add = F){
  stopifnot(
    'gene names in vector not represented in data frame' = vectornames %in% row.names(weight_data),
    'vectornames is not a character vector' = is.vector(vectornames, mode = 'character')
  )
  
  # if no maxn is given all possible combinations will be built
  if(missing(maxn)){
      maxn = length(vectornames)
    }
    
    # prepare combinations of defined length
    if(add == F){
    res = Map(combn, list(vectornames), seq_along(c(1:maxn)), simplyfy = F)
    test = unlist(res, recursive = FALSE)
    vectors = list()
    z=1
    for(i in 1:(length(res))){
      for(j in 1:(length(res[[i]])/length(res[[i]][ ,1]) ) ){
        vectors[[z]] = res[[i]][,j]
        z = z + 1
      }
    }
    }
  # if add is set to TRUE, combinations are only adding one protein after the other in order they are given (going from legnth 1 to length of vectornames)
  else{
    vectors = list()
    z=1
    for(i in 1:(length(vectornames))){
      
      vectors[[i]] = vectornames[1:i]
      z = z + 1
    }
  }
  
  ## put combinations into empty dataframe
  savespace = data.frame(combinations = I(vectors))
  savespace$auc = NA
  
  ## add auc for the combinations
  for(i in 1:nrow(savespace)){
    interim = as.data.frame(weight_data)
    # set all weights that are not in the combination of interes to 0
    interim[! row.names(interim) %in% vectors[[i]], "V1"] = 0
    # predict 0 or 1 by using the linear regression formula (y = w1*x1+ .... w_n*x_n)
    interim_pred = as.matrix(as.matrix(protein_data[ ,!names(protein_data)=='status']) %*% as.matrix(interim))
    # use glmnet function to calculate the auc between actual status and the calculated status, i.e. prediction
    savespace$auc[i] = glmnet:::auc(interim_pred,protein_data$status)
  }

  savespace$combinations = lapply(savespace$combinations, function(X) paste0(X,collapse = ", "))
  return(savespace)
}
```

#### 1.5.6 Sens & Spec

```{r specificity and sensitivity function}

spec_and_sens= function(data_frame){
      #create vectors for values
      spec = sens = rep(NA,length(data_frame[["models"]]))
      
      #pull out model performance values
      for(i in 1:length(data_frame[["models"]])){
        spec[i] = as.numeric(data_frame[["models"]][[i]][["results"]]["Spec"])
        sens[i] = as.numeric(data_frame[["models"]][[i]][["results"]]["Sens"])
      }
      
      #return means of specificty and sensitivity
      return(cat("mean specificity is ", round(mean(spec),2), " and mean sensitivity is ", round(mean(sens),2)))
}

```


### 1.6 Supervised machine learning

For upcoming analysis, we will set the number of bootstrapping to 'bs'

```{r set number of bootstrapping}
bs=500
```

```{r adjust status column}
df_ml$status = (as.numeric(df_ml$status)-1)

write.csv(df_ml, file = 'results/df_ml.csv')
```


#### 1.6.1 Linear Regression

##### 1.6.1.1 Only proteomics data

Linear regression is run using AUC to pick the best model, using glmnet algorithm, binomial distribution, and lasso.

```{r run linear regression,results='hide',eval = F}
if(file.exists('results/new_linearModel.rds')){
  lm = readRDS(file = 'results/new_linearModel.rds')
}else{
      #run model
      lm = runML(df_ml,'lm', BS_number = bs)
      
      # save results for later use
      saveRDS(lm, file = 'results/new_linearModel.rds')
  }
```



```{r save and plot results linear regression,results='hide', eval = F}
#construct ROC curve
ROC_curve = calculateROC_jpeg(lm,df_ml,'plots/new_rocc_lm.pdf','plots/new_rocc_lm.jpeg')

# save results for later use
write.csv(ROC_curve, file = 'results/new_rocc_lm.csv')

lm_weights = plotWeights_jpeg(lm,"plots/new_weights_lm.pdf","plots/new_weights_lm.jpeg")
# save results for later use
write.csv(lm_weights, file = 'results/new_weights_lm.csv')

```

The results of the linear regression:

![Linear regression weights](plots/new_weights_lm.jpeg)
![Linear regression ROC](plots/new_rocc_lm.jpeg)

##### 1.6.1.2 With clinical variables

```{r remove unnecessary info from clinical data}
#remove patients that are also not in the final dataset and merge datasets
df_ml_clin = p_d2[,!names(p_d2) == c("patid","status.x","onset")]
colnames(df_ml_clin)[colnames(df_ml_clin)=="status.y"] = "status"
df_ml_clin$status = (as.numeric(as.factor(df_ml_clin$status)))-1
df_ml_clin$sex = (as.numeric(as.factor(df_ml_clin$sex)))-1

write.csv(df_ml_clin, file = 'results/df_ml_clin.csv')
```


```{r run linear regression with clinical variables,results='hide',eval = F}

if(file.exists('results/new_clin_linearModel.rds')){
  lm = readRDS(file = 'results/new_clin_linearModel.rds')
}else{
      #run model
      lm = runML(df_ml_clin,'lm', BS_number = bs)
      
      # save results for later use
      saveRDS(lm, file = 'results/new_clin_linearModel.rds')
  }
```


```{r plot results linear regression with clinical variables,results='hide', eval = F}

#plot ROC curve
ROC_curve = calculateROC_jpeg(lm,df_ml,'plots/new_clin_rocc_lm.pdf','plots/new_clin_rocc_lm.jpeg')

# save results for later use
write.csv(ROC_curve, file = 'results/new_clin_rocc_lm.csv')


# extract weights + plot averaged
lm_weights = plotWeights_jpeg(lm,"plots/new_clin_weights_lm.pdf","plots/new_clin_weights_lm.jpeg")
# save results for later use
write.csv(lm_weights, file = 'results/new_clin_weights_lm.csv')
```

The results of the linear regression:

![Linear regression weights](plots/new_clin_weights_lm.jpeg)
![Linear regression ROC](plots/new_clin_rocc_lm.jpeg)

```{r scatterplot with weights lm}
# load weights data
w = read.csv(file = 'results/new_weights_lm.csv')
w_clin = read.csv(file = 'results/new_clin_weights_lm.csv')

#merge on gene name
w_comb <- merge(w, w_clin, by = "X")

#scatterplot
plot(x = w_comb$avg.x, y = w_comb$avg.y, xlab = "proteins weights in lm with clinical data", ylab = "proteins weights in lm without clinical data")
```

##### 1.6.1.3 With top quantile according to DE analysis

```{r take top quantile according to FDR}
q = rownames(DE)[1:(nrow(DE)/4)]
```


```{r run linear regression DE quantile, results='hide',eval = F}
if(file.exists('results/new_linearModel_topquantile.rds')){
  lm = readRDS(file = 'results/new_linearModel_topquantile.rds')
}else{
      #run model
      lm = runML(df_ml[,c("status",q)],'lm', BS_number = bs)
      
      # save results for later use
      saveRDS(lm, file = 'results/new_linearModel_topquantile.rds')
  }
```



```{r save and plot results linear regression,results='hide', eval = F}
# plot averaged ROC curve
ROC_curve = calculateROC_jpeg(lm,df_ml[,c("status",q)],'plots/new_rocc_lm_topquantile.pdf','plots/new_rocc_lm_topquantile.jpeg')

# save results for later use
write.csv(ROC_curve, file = 'results/new_rocc_lm_topquantile.csv')


# extract weights + plot averaged
lm_weights = plotWeights_jpeg(lm,"plots/new_weights_lm_topquantile.pdf","plots/new_weights_lm_topquantile.jpeg")
# save results for later use
write.csv(lm_weights, file = 'results/new_weights_lm_topquantile.csv')

```

#### 1.6.2 Random Forest

##### 1.6.2.1 Only using proteomics data

```{r random forest proteomics data, results='hide',cache=TRUE,eval=F}
if(file.exists('results/new_randomForest.rds')){
  rf = readRDS(file = 'results/new_randomForest.rds')
}else{
      #run model
      rf = runML(df_ml,'rf', BS_number = bs)
      
      # save results for later use
      saveRDS(rf, file = 'results/new_randomForest.rds')
}
```



```{r random forest proteomics data visuals, results='hide',cache=TRUE,eval=F}
# plot averaged ROC curve
# takes result object from runML(), the original data frame and path to save plot (optional)
# returns data frame with values for plot
ROC_curve_rf = calculateROC_jpeg(rf,df_ml,'plots/new_rocc_rf.pdf','plots/new_rocc_rf.jpeg')

# save results for later use
write.csv(ROC_curve_rf, file = 'results/new_rocc_rf.csv')

# extract weights + plot averaged
# arguments:  list_from_ML: results from runML()
#             plot_path:    path to save plot(optional)
#             number:       number of proteins on plot
# returns data frame with values for plot
rf_importance = plotWeights_jpeg(rf,'plots/new_importance_rf.pdf','plots/new_importance_rf.jpeg')
# save results for later use
write.csv(rf_importance, file = 'results/new_importance_rf.csv')
```

![Random forest weights](plots/new_importance_rf.jpeg)
![Random forest ROC](plots/new _rocc_rf.jpeg)


##### 1.6.2.2 Added age and sex

```{r random forest proteomics data and clinical data, results='hide',cache=TRUE,eval=F}
if(file.exists('results/new_clin_randomForest.rds')){
  rf = readRDS(file = 'results/new_clin_randomForest.rds')
}else{
      #run model
      rf = runML(df_ml_clin,'rf', BS_number = bs)
      
      # save results for later use
      saveRDS(rf, file = 'results/new_clin_randomForest.rds')
}
```


```{r random forest proteomics data and clinical data visuals, results='hide',cache=TRUE,eval=F}
# plot averaged ROC curve
ROC_curve_rf = calculateROC_jpeg(rf,df_ml,'plots/new_clin_rocc_rf.pdf','plots/new_clin_rocc_rf.jpeg')

# save results for later use
write.csv(ROC_curve_rf, file = 'results/new_clin_rocc_rf.csv')

# extract weights + plot averaged

rf_importance = plotWeights_jpeg(rf,'plots/new_clin_importance_rf.pdf','plots/new_clin_importance_rf.jpeg')
# save results for later use
write.csv(rf_importance, file = 'results/new_clin_importance_rf.csv')
```

![Random forest weights](plots/new_clin_importance_rf.jpeg)
![Random forest ROC](plots/new_clin_rocc_rf.jpeg)

##### 1.6.2.3 With only top quantile

```{r random forest proteomics data quantiles, results='hide',cache=TRUE,eval=F}
if(file.exists('results/new_randomForest_topquantile.rds')){
  rf = readRDS(file = 'results/new_randomForest_topquantile.rds')
}else{
      #run model
      rf = runML(df_ml[,c("status",q)],'rf', BS_number = bs)
      
      # save results for later use
      saveRDS(rf, file = 'results/new_randomForest_topquantile.rds')
}
```



```{r random forest proteomics data visuals quantiles, results='hide',cache=TRUE,eval=F}
# plot averaged ROC curve
ROC_curve_rf = calculateROC_jpeg(rf,df_ml[,c("status",q)],'plots/new_rocc_rf_topquantile.pdf','plots/new_rocc_rf_topquantile.jpeg')

# save results for later use
write.csv(ROC_curve_rf, file = 'results/new_rocc_rf_topquantile.csv')

# extract weights + plot averaged
rf_importance = plotWeights_jpeg(rf,'plots/new_importance_rf_topquantile.pdf','plots/new_importance_rf_topquantile.jpeg')
# save results for later use
write.csv(rf_importance, file = 'results/new_importance_rf_topquantile.csv')
```

#### 1.6.3 Support Vector Machine

##### 1.6.3.1 Only proteomics data

```{r support vector machine linear, results='hide',cache=TRUE,eval=F}
if(file.exists('results/new_svm_lin.rds')){
  new_svm_l = readRDS(file = 'results/new_svm_lin.rds')
}else{
      #run model
      new_svm_l = runML(df_ml,'svm lin', BS_number = bs)
      
      # save results for later use
      saveRDS(new_svm_l, file = 'results/new_svm_lin.rds')
}
```

```{r support vector machine linear visuals, results='hide',cache=TRUE,eval=F}
# plot averaged ROC curve
new_ROC_curve_l = calculateROC_jpeg(new_svm_l,df_ml,'plots/new_rocc_svml.pdf','plots/new_rocc_svml.jpeg')

# save results for alter use
write.csv(new_ROC_curve_l, file = 'results/new_rocc_svml.csv')


# extract weights + plot averaged
new_svml_weights = plotWeights_jpeg(new_svm_l,"plots/new_weights_svml.pdf","plots/new_weights_svml.jpeg")
# save results for later use
write.csv(new_svml_weights, file = 'results/new_weights_svml.csv')
```

```{r support vector machine radial, results='hide',cache=TRUE,eval=F}
if(file.exists('results/new_svm_rad.rds')){
  new_svm_r = readRDS(file = 'results/new_svm_rad.rds')
}else{
      #run model
      new_svm_r = runML(df_ml,'svm rad', BS_number = bs)
      
      # save results for later use
      saveRDS(new_svm_r, file = 'results/new_svm_rad.rds')
}
```


```{r support vector machine radial visuals, results='hide',cache=TRUE,eval=F}
# plot averaged ROC curve
new_ROC_curve_r = calculateROC_jpeg(new_svm_r,df_ml,'plots/new_rocc_svmr.pdf','plots/new_rocc_svmr.jpeg')

# save results for alter use
write.csv(new_ROC_curve_r, file = 'results/new_rocc_svmr.csv') 
```


![SVM weights linear kernel](plots/new_weights_svml.jpeg)
![ROC plot SVM linear kernel](plots/new_rocc_svml.jpeg)

![ROC plot SVM radial kernel](plots/new_rocc_svmr.jpeg)

##### 1.6.3.2 Adding age and sex

```{r support vector machine linear with clinical data, results='hide',cache=TRUE,eval=F}
if(file.exists('results/new_clin_svm_lin.rds')){
  new_svm_l = readRDS(file = 'results/new_clin_svm_lin.rds')
}else{
      #build model
      new_svm_l = runML(df_ml_clin,'svm lin', BS_number = bs)
      
      # save results for later use
      saveRDS(new_svm_l, file = 'results/new_clin_svm_lin.rds')
}

```


```{r support vector machine linear with clinical data visuals, results='hide',cache=TRUE,eval=F}
# plot averaged ROC curve
new_ROC_curve_l = calculateROC_jpeg(new_svm_l,df_ml,'plots/new_clin_rocc_svml.pdf','plots/new_clin_rocc_svml.jpeg')


# save results for alter use
write.csv(new_ROC_curve_l, file = 'results/new_clin_rocc_svml.csv')

# extract weights + plot averaged
new_svml_weights = plotWeights_jpeg(new_svm_l,"plots/new_clin_weights_svml.pdf","plots/new_clin_weights_svml.jpeg")
# save results for later use
write.csv(new_svml_weights, file = 'results/new_clin_weights_svml.csv')
```

```{r support vector machine radial with clinical data, results='hide',cache=TRUE,eval=F}
if(file.exists('results/new_clin_svm_rad.rds')){
  new_svm_r = readRDS(file = 'results/new_clin_svm_rad.rds')
}else{
      #run model
      new_svm_r = runML(df_ml_clin,'svm rad', BS_number = bs)
      
      # save results for later use
      saveRDS(new_svm_r, file = 'results/new_clin_svm_rad.rds')
}
```


```{r support vector machine radial with clinical data visuals, results='hide',cache=TRUE,eval=F}
# plot averaged ROC curve
# takes result object from runML(), the original data frame and path to save plot (optional)
# returns data frame with values for plot

new_ROC_curve_r = calculateROC_jpeg(new_svm_r,df_ml,'plots/new_clin_rocc_svmr.pdf','plots/new_clin_rocc_svmr.jpeg')

# save results for alter use

write.csv(new_ROC_curve_r, file = 'results/new_clin_rocc_svmr.csv') 
```


![SVM weights linear kernel](plots/new_clin_weights_svml.jpeg)

![ROC plot SVM linear kernel](plots/new_clin_rocc_svml.jpeg)


![ROC plot SVM radial kernel](plots/new_clin_rocc_svmr.jpeg)

##### 1.6.3.3 With only top quantile

```{r support vector machine linear, results='hide',cache=TRUE,eval=F}
if(file.exists('results/new_svm_lin_topquantile.rds')){
  new_svm_l = readRDS(file = 'results/new_svm_lin_topquantile.rds')
}else{
      #run model
      new_svm_l = runML(df_ml[,c("status",q)],'svm lin', BS_number = bs)
      
      # save results for later use
      saveRDS(new_svm_l, file = 'results/new_svm_lin_topquantile.rds')
}
```

```{r support vector machine linear visuals, results='hide',cache=TRUE,eval=F}
# plot averaged ROC curve
new_ROC_curve_l = calculateROC_jpeg(new_svm_l,df_ml[,c("status",q)],'plots/new_rocc_svml_topquantile.pdf','plots/new_rocc_svml_topquantile.jpeg')

# save results for alter use
write.csv(new_ROC_curve_l, file = 'results/new_rocc_svml_topquantile.csv')


# extract weights + plot averaged
new_svml_weights = plotWeights_jpeg(new_svm_l,"plots/new_weights_svml_topquantile.pdf","plots/new_weights_svml_topquantile.jpeg")
# save results for later use
write.csv(new_svml_weights, file = 'results/new_weights_svml_topquantile.csv')
```

```{r support vector machine radial, results='hide',cache=TRUE,eval=F}
if(file.exists('results/new_svm_rad_topquantile.rds')){
  new_svm_r = readRDS(file = 'results/new_svm_rad_topquantile.rds')
}else{
      #run model
      new_svm_r = runML(df_ml[,c("status",q)],'svm rad', BS_number = bs)
      
      # save results for later use
      saveRDS(new_svm_r, file = 'results/new_svm_rad_topquantile.rds')
}
```


```{r support vector machine radial visuals, results='hide',cache=TRUE,eval=F}
# plot averaged ROC curve
new_ROC_curve_r = calculateROC_jpeg(new_svm_r,df_ml[,c("status",q)],'plots/new_rocc_svmr_topquantile.pdf','plots/new_rocc_svmr_topquantile.jpeg')

# save results for alter use
write.csv(new_ROC_curve_r, file = 'results/new_rocc_svmr_topquantile.csv') 
```

##### 1.6.3.3 Scatterplot both weights VWM

```{r scatterplot with weights SVM}
# load weights data
w = read.csv(file = 'results/new_weights_svml.csv')
w_clin = read.csv(file = 'results/new_clin_weights_svml.csv')

#merge on gene name
w_comb <- merge(w, w_clin, by = "X")

#scatterplot
plot(x = w_comb$avg.x, y = w_comb$avg.y, xlab = "proteins weights in SVM with clinical data", ylab = "proteins weights in SVM without clinical data")
```


### 1.7 Gene set enrichment analysis

#### 1.7 With linear model

```{r gene set enrichment analysis with linear model,eval=F}

# load data for background
background_data = read.csv(file = 'results/new_background_for_gsea.csv')[,2]

## get gene set to 
lm_genes = read.csv('results/new_weights_lm.csv', row.names = 1)
lm_genes = setNames(lm_genes$avg,row.names(lm_genes))

# run fgsea
# arguments:  genes: named (gene name) vector with values (either geneXexpression, or weights from ML models)
#             min_size: min number of genes to be found in a pathway for it to show up in results (default = 3)
#             plot_path: path to save plot (optional)
#             number: number of pathways included in the plot (default = 20)
#             entrezID: logical, if input data (gene names and background) is entrezid or gene name
#             background: vector with background genes (optional)
# returns # returns data frame with values for plot
gsea_result = gsea_jpeg(lm_genes,background = background_data, min_size = 1, plot_path_pdf = 'plots/new_lm_fgsea.pdf',plot_path_jpeg = 'plots/new_lm_fgsea.jpeg')

```

![Gene set enrichment analysis](plots/new_fgsea.jpeg)

```{r gene set enrichment analysis with support vector machine,eval=F}
# load data for background
background_data = read.csv(file = 'results/new_background_for_gsea.csv')[,2]

## get gene set to 
svm_genes = read.csv('results/new_weights_svml.csv', row.names = 1)
svm_genes = setNames(svm_genes$avg,row.names(svm_genes))

# run fgsea
# arguments:  genes: named (gene name) vector with values (either geneXexpression, or weights from ML models)
#             min_size: min number of genes to be found in a pathway for it to show up in results (default = 3)
#             plot_path: path to save plot (optional)
#             number: number of pathways included in the plot (default = 20)
#             entrezID: logical, if input data (gene names and background) is entrezid or gene name
#             background: vector with background genes (optional)
# returns # returns data frame with values for plot
gsea_result = gsea_jpeg(svm_genes,background = background_data, min_size = 1, plot_path_pdf = 'plots/new_svm_fgsea.pdf', plot_path_jpeg = 'plots/new_svm_fgsea.jpeg')

```

![Gene set enrichment analysis](plots/new_svm_fgsea.jpeg)

### 1.8 Visualization differential expression analysis 

```{r load data generated in Perseus}
DE <- read.delim2("DE_Perseus_analysis/DEdataknnimputed01standardized.txt", comment.char="#")
rownames(DE) = DE$X

DE = DE[-1,]
```


```{r use ggplot for visualizations, results='hide'}
##Identify the genes that have a p-value < 0.05
DE$threshold.05 = as.factor(DE$X0_vs_1_PValue < 0.05)
DE$threshold.1 = as.factor(DE$X0_vs_1_PValue < 0.1)

##Construct the plot object
ggplot(data=DE, 
            aes(x=X0_vs_1_logFC, y = X0_vs_1_.log.PValue., 
            colour=threshold.1)) +
  geom_point(alpha=0.4, size=1.75) +
  xlim(c(-3, 3)) +
  xlab("log2 fold change") + ylab("-log10 p-value") +
  theme_bw() +
  theme(legend.position="none") +
  geom_text(aes(label=ifelse(X0_vs_1_PValue<0.1,as.character(rownames(DE)),'')),hjust=0,vjust=0) + 
  scale_color_viridis(discrete=TRUE, direction = -1)

ggsave("plots/new_DE_volcano.jpg", width = 6, height = 4, units = "in")
ggsave("plots/new_DE_volcano.pdf", width = 11, height = 8, units = "in")
```

```{r create list of upregulated or downregulated genes}
DE_sig = DE[DE$threshold==TRUE,100:108]
DE_sig = DE_sig[order(DE_sig$X0_vs_1_PValue, decreasing = FALSE), ]
write.csv(DE_sig, file = 'results/DE_up_or_down_regulated_genes.csv')

DE_sig_up = DE_sig[DE_sig$X0_vs_1_logFC>0,]
DE_sig_down = DE_sig[DE_sig$X0_vs_1_logFC<0,]
write.csv(DE_sig_up, file = 'results/DE_up_regulated_genes.csv')
write.csv(DE_sig_down, file = 'results/DE_down_regulated_genes.csv')
```

```{r look at the 9 most important genes}

prot = c("CRYM", "CAPZA2", "ALDH16A1", "PFKL", "SERPINC1", "HP", "EIF2S2", "GMPPA", "SCGB1D1")
DE[prot,99:108]
DE$X0_vs_1_logFC
```


